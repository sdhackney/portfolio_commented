{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\"> <h1 style=\"color:green; margin-bottom:20px\">Reviewer's comment v1</h1>\n",
    "\n",
    "Hello Spencer, my name is Dmitrii. I'm going to review your project! Nice to meet you! üôå\n",
    "\n",
    "You can find my comments under the heading **¬´Review¬ª**. I will categorize my comments in green, blue or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> if everything is done successfully\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> if I can give some recommendations or ways to improve the project\n",
    "   \n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> if the block requires some corrections. Work can't be accepted with the red comments\n",
    "</div>\n",
    "\n",
    "Please don't remove my comments :) If you have any questions don't hesitate to respond to my comments in a different section. \n",
    "<div class=\"alert alert-info\"> <b>Student comments:</b> For example like this</div>   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "<b>Overall Feedback</b> \n",
    "    \n",
    "\n",
    "You've done a really good job overall! Your work shows that you understand the topic well and you've put in a lot of effort. There are a few small things to work on, but nothing too big:\n",
    "    \n",
    "    - Update the file path. \n",
    "    - Upate logic in the model evaluation stage.\n",
    "    \n",
    "Keep going like this, and with a little bit of tweaking, your work will be even better. I will wait for you to send me a new version of the project :)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v2:</b>\n",
    "    \n",
    "<b>Overall Feedback</b> \n",
    "    \n",
    "Thank you for your comments and for going the extra mile in incorporating additional changes and improvements. \n",
    "\n",
    "\n",
    "Wish you cool projects in the next sprints! ‚òòÔ∏è\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a project to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. \n",
    "\n",
    "# I have access to behavior data about subscribers who have already switched to the new plans. For this classification task, I will develop a model that will pick the right plan.   \n",
    "\n",
    "# I will develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. \n",
    "\n",
    "#  The data preprocessing step has already been completed, I will move straight to creating the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "It is always helpful for the reader to have additional information about project tasks. It gives an overview of what you are going to achieve in this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing packages I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing users_behavior dataset as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Unfortunately, the file path is not correct here. Could you please check that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">  I uploaded the dataset to jupyter and that is how I called it. That is how I have been doing it throughout this course. I am not sure what is going wrong. When I hit Kernel and restart and run all it works. </div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Reviewer's comment v2</b>\n",
    " \n",
    "This is a correct remote file path `'/datasets/users_behavior.csv'` \n",
    "    \n",
    "You can use try/except structure in the following way to combine both paths: \n",
    "    \n",
    "    \n",
    "```\n",
    "try:\n",
    "    orders = pd.read_csv('users_behavior.csv', sep=';')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    orders = pd.read_csv('/datasets/users_behavior.csv', sep=';')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "It's a good practice to use `try/except blocks` when performing file operations or other tasks that might fail due to external reasons, such as the file not being present, issues with file permissions, or incorrect file formats. This way, you can handle errors gracefully and provide a more user-friendly error message, rather than having the program crash unexpectedly.\n",
    "\n",
    "Here's how you can implement it:\n",
    "\n",
    "```\n",
    "try:\n",
    "    orders = pd.read_csv(local_path['Churn.csv'], sep=';')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    orders = pd.read_csv(server_path['Churn.csv'], sep=';')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">  I tried doing this but it said that the local_path wasn't defined or something like that </div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there are 3214 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>26.0</td>\n",
       "      <td>201.35</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9027.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>72.0</td>\n",
       "      <td>410.23</td>\n",
       "      <td>68.0</td>\n",
       "      <td>16006.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>39.0</td>\n",
       "      <td>257.93</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6572.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>39.0</td>\n",
       "      <td>278.79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11430.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>61.0</td>\n",
       "      <td>421.74</td>\n",
       "      <td>41.0</td>\n",
       "      <td>19746.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>32.0</td>\n",
       "      <td>244.80</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7213.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>41.0</td>\n",
       "      <td>302.04</td>\n",
       "      <td>106.0</td>\n",
       "      <td>9755.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>111.0</td>\n",
       "      <td>717.16</td>\n",
       "      <td>191.0</td>\n",
       "      <td>38287.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>45.0</td>\n",
       "      <td>270.14</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>45.0</td>\n",
       "      <td>358.45</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12715.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>18.0</td>\n",
       "      <td>147.93</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1904.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>53.0</td>\n",
       "      <td>354.85</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21820.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "1818   26.0   201.35      32.0   9027.27         1\n",
       "860    72.0   410.23      68.0  16006.55         0\n",
       "207    39.0   257.93      15.0   6572.61         0\n",
       "3075   39.0   278.79      21.0  11430.52         0\n",
       "923    61.0   421.74      41.0  19746.94         0\n",
       "1340   32.0   244.80      13.0   7213.58         0\n",
       "1305   41.0   302.04     106.0   9755.95         0\n",
       "227   111.0   717.16     191.0  38287.82         1\n",
       "2978   45.0   270.14      29.0      0.00         1\n",
       "2993   45.0   358.45      55.0  12715.68         0\n",
       "651    18.0   147.93      18.0   1904.01         1\n",
       "1215   53.0   354.85      10.0  21820.27         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "Before using data for any ML model, it could be helpful to check for duplicates, verify the uniqueness of values, and identify any nulls.\n",
    "    \n",
    "Consider visualizing some key aspects of the data (e.g., distribution of variables, correlation matrix) to provide a better understanding of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">  I did not do any of this because the project description says \"Since you‚Äôve already performed the data preprocessing step, you can move straight to creating the model.\"  </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v2:</b>\n",
    "    \n",
    "üëç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this is a classification model. is_ultra will be my target. calls, minutes, messages, mb_used will be my features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features df has 4 columns meaning the is_ultra column has been dropped and the target df only has 1 column, is_ultra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345, stratify=df['is_ultra'])\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2410, 4)\n",
      "(2410,)\n",
      "(804, 4)\n",
      "(804,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "The data split is correct.  However, consider using `stratify` parameter in train_test_split to maintain the distribution of the target variable, especially important for imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing the decision tree classifier model with different depths for highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7325870646766169\n",
      "max_depth = 2 : 0.7674129353233831\n",
      "max_depth = 3 : 0.7723880597014925\n",
      "max_depth = 4 : 0.7960199004975125\n",
      "max_depth = 5 : 0.7860696517412935\n",
      "max_depth = 6 : 0.7922885572139303\n",
      "max_depth = 7 : 0.7960199004975125\n",
      "max_depth = 8 : 0.7898009950248757\n",
      "max_depth = 9 : 0.7960199004975125\n",
      "max_depth = 10 : 0.7960199004975125\n",
      "max_depth = 11 : 0.7910447761194029\n",
      "max_depth = 12 : 0.7835820895522388\n",
      "max_depth = 13 : 0.7748756218905473\n",
      "max_depth = 14 : 0.7798507462686567\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=12345) \n",
    "    model.fit(features_train, target_train)  \n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    print(\"max_depth =\", depth, \": \", end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max depth 7 got the highest accuracy with .7898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### even though this meets the threshold, there might be a better model with a higher accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing the accuracy of the Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the validation set (n_estimators = 10): 0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 15):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) \n",
    "    model.fit(features_train, target_train) \n",
    "    score = model.score(features_valid, target_valid) \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model has a higher accuracy than the Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Logistic Regression Model for highest acccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7153526970954357\n",
      "Accuracy of the logistic regression model on the validation set: 0.7114427860696517\n"
     ]
    }
   ],
   "source": [
    "model =  LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)  \n",
    "score_train = model.score(\n",
    "    features_train, target_train\n",
    ")  \n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the training set:\",\n",
    "    score_train,\n",
    ")\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the validation set:\",\n",
    "    score_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "Everything is correct here! Great that you've managed to check multiple models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression has the lowest accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will be using the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=12, random_state=12345)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7935323383084577\n"
     ]
    }
   ],
   "source": [
    "test_predictions = final_model.predict(features_valid)\n",
    "\n",
    "def accuracy(answers, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(answers)):\n",
    "        if answers.iloc[i] == predictions[i]:  \n",
    "            correct += 1\n",
    "    return correct / len(answers)\n",
    "\n",
    "print('Accuracy:', accuracy(target_valid, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after training the model on the training set and testing it on the valid set I received an accuracy score of 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "You've trained your model on the entire dataset `(features, target)` and then evaluated it on the same dataset. This practice leads to overly optimistic performance estimates because the model is being tested on data it has already seen. The high accuracy score of nearly 100% is thus not a reliable indicator of how well your model would perform on truly unseen data.\n",
    "\n",
    "You should fit your model using only the `features_train` and `target_train` datasets.\n",
    "After fitting the model, you make predictions on the `features_valid` dataset, which the model has not seen during training.\n",
    "The accuracy (or any other performance metric) should then be calculated based on how well the model's predictions on the validation set (`features_valid`) match the actual targets in target_valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v2:</b>\n",
    "\n",
    "Everything is correct now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "In our case, we have a very skewed distribution of users across the two plans. As you can see, only 30% are enrolled in the Ultra plan, therefore it could be usefull to have a dummy model in place to validate results of the RandomForestClassifier.  \n",
    "    \n",
    "You could use `DummyClassifier` to implement this sanity check. You could read about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "    \n",
    "```\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# Initialize the DummyClassifier to predict the most frequent class\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=0)\n",
    "# Fit the dummy classifier on the training data\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In conclusion, the model Random Forest Classifier  with the number of estimators set to 12 will give almost 80% accuracy in determining what plan to offer a customer based off of what their data shows on their calls, minutes, messages, and mb used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "\n",
    "Great job on your overall conclusions and recommendations!  Your recommendations are well-thought and could be very valuable to the business."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
